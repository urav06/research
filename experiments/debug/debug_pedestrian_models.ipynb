{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Model Debugging: Pedestrian Dataset\n",
    "\n",
    "No-frills debugging notebook to test 8 TSC models on pedestrian dataset.\n",
    "- Dataset: Pedestrian (10% training, 50% testing)\n",
    "- Models: All 8 algorithms from tsckit\n",
    "- Error handling: NONE - let errors throw with full stack traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Paths configured successfully!\n"
     ]
    }
   ],
   "source": [
    "# Setup paths BEFORE importing tsckit (CRITICAL!)\n",
    "import sys\n",
    "\n",
    "# Add all necessary paths for algorithm imports\n",
    "sys.path.extend([\n",
    "    '/Users/urav/code/research',                    # For tsckit package\n",
    "    '/Users/urav/code/research/quant/code',         # For original quant.py\n",
    "    '/Users/urav/code/research/hydra/code',         # For original hydra.py  \n",
    "    '/Users/urav/code/research/aaltd2024/code',     # For quant_aaltd.py, hydra_gpu.py, utils.py, ridge.py\n",
    "])\n",
    "\n",
    "print(\"✓ Paths configured successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All imports successful!\n"
     ]
    }
   ],
   "source": [
    "# Import TSCKIT and required libraries\n",
    "from tsckit import (\n",
    "    MonsterDataset, \n",
    "    QuantOriginal, QuantAALTD2024,\n",
    "    HydraOriginal, HydraAALTD2024,\n",
    "    HydraQuantStackedAALTD2024,  # Old ensemble (has data leakage)\n",
    "    HydraQuantStacked,           # New clean ensemble (with proper CV)\n",
    "    AeonAlgorithm\n",
    ")\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "print(\"✓ All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created:\n",
      "Pedestrian (fold 0):\n",
      "  Shape: 1 channels x 24 time points\n",
      "  Classes: 82\n",
      "  Total samples: 189621\n",
      "  Train samples: 1516 (1%)\n",
      "  Test samples: 379 (1%)\n",
      "\n",
      "Test labels loaded: (379,)\n",
      "Number of classes: 79\n"
     ]
    }
   ],
   "source": [
    "# Create pedestrian dataset: 10% train, 50% test\n",
    "dataset = MonsterDataset(\"Pedestrian\", fold=0, train_pct=1, test_pct=1)\n",
    "print(\"Dataset created:\")\n",
    "print(dataset.info())\n",
    "\n",
    "# Load ground truth for later accuracy calculation\n",
    "_, y_test = dataset.get_arrays(\"test\")\n",
    "print(f\"\\nTest labels loaded: {y_test.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: QuantOriginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing QuantOriginal...\n",
      "Model: QuantOriginal(depth=6, div=4)\n",
      "Training completed in 0.421s\n",
      "Prediction completed in 0.033s\n",
      "Accuracy: 0.5303\n",
      "Predictions shape: (379,)\n",
      "✓ QuantOriginal PASSED\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing QuantOriginal...\")\n",
    "model1 = QuantOriginal(depth=6)\n",
    "print(f\"Model: {model1.name}\")\n",
    "\n",
    "start_time = time.time()\n",
    "model1.fit(dataset)\n",
    "train_time = time.time() - start_time\n",
    "print(f\"Training completed in {train_time:.3f}s\")\n",
    "\n",
    "start_time = time.time()\n",
    "predictions1 = model1.predict(dataset)\n",
    "pred_time = time.time() - start_time\n",
    "print(f\"Prediction completed in {pred_time:.3f}s\")\n",
    "\n",
    "accuracy1 = np.mean(predictions1 == y_test)\n",
    "print(f\"Accuracy: {accuracy1:.4f}\")\n",
    "print(f\"Predictions shape: {predictions1.shape}\")\n",
    "print(\"✓ QuantOriginal PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: HydraOriginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing HydraOriginal...\n",
      "Model: HydraOriginal(k=4, g=16, seed=42)\n",
      "Training completed in 0.149s\n",
      "Prediction completed in 0.016s\n",
      "Accuracy: 0.3799\n",
      "Predictions shape: (379,)\n",
      "✓ HydraOriginal PASSED\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing HydraOriginal...\")\n",
    "model2 = HydraOriginal(k=4, g=16, seed=42)\n",
    "print(f\"Model: {model2.name}\")\n",
    "\n",
    "start_time = time.time()\n",
    "model2.fit(dataset)\n",
    "train_time = time.time() - start_time\n",
    "print(f\"Training completed in {train_time:.3f}s\")\n",
    "\n",
    "start_time = time.time()\n",
    "predictions2 = model2.predict(dataset)\n",
    "pred_time = time.time() - start_time\n",
    "print(f\"Prediction completed in {pred_time:.3f}s\")\n",
    "\n",
    "accuracy2 = np.mean(predictions2 == y_test)\n",
    "print(f\"Accuracy: {accuracy2:.4f}\")\n",
    "print(f\"Predictions shape: {predictions2.shape}\")\n",
    "print(\"✓ HydraOriginal PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: QuantAALTD2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing QuantAALTD2024...\n",
      "Model: QuantAALTD2024(n_estimators=50)\n",
      "Training completed in 0.107s\n",
      "Prediction completed in 0.021s\n",
      "Accuracy: 0.5145\n",
      "Predictions shape: (379,)\n",
      "✓ QuantAALTD2024 PASSED\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing QuantAALTD2024...\")\n",
    "model3 = QuantAALTD2024(num_estimators=50)\n",
    "print(f\"Model: {model3.name}\")\n",
    "\n",
    "start_time = time.time()\n",
    "model3.fit(dataset)\n",
    "train_time = time.time() - start_time\n",
    "print(f\"Training completed in {train_time:.3f}s\")\n",
    "\n",
    "start_time = time.time()\n",
    "predictions3 = model3.predict(dataset)\n",
    "pred_time = time.time() - start_time\n",
    "print(f\"Prediction completed in {pred_time:.3f}s\")\n",
    "accuracy3 = np.mean(predictions3 == y_test)\n",
    "print(f\"Accuracy: {accuracy3:.4f}\")\n",
    "print(f\"Predictions shape: {predictions3.shape}\")\n",
    "print(\"✓ QuantAALTD2024 PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: HydraAALTD2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing HydraAALTD2024...\n",
      "Model: HydraAALTD2024(k=4, g=16, seed=42)\n",
      "Training completed in 0.083s\n",
      "Prediction completed in 0.013s\n",
      "Accuracy: 0.3641\n",
      "Predictions shape: (379,)\n",
      "✓ HydraAALTD2024 PASSED\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing HydraAALTD2024...\")\n",
    "model4 = HydraAALTD2024(k=4, g=16, seed=42)\n",
    "print(f\"Model: {model4.name}\")\n",
    "\n",
    "start_time = time.time()\n",
    "model4.fit(dataset)\n",
    "train_time = time.time() - start_time\n",
    "print(f\"Training completed in {train_time:.3f}s\")\n",
    "\n",
    "start_time = time.time()\n",
    "predictions4 = model4.predict(dataset)\n",
    "pred_time = time.time() - start_time\n",
    "print(f\"Prediction completed in {pred_time:.3f}s\")\n",
    "accuracy4 = np.mean(predictions4 == y_test)\n",
    "print(f\"Accuracy: {accuracy4:.4f}\")\n",
    "print(f\"Predictions shape: {predictions4.shape}\")\n",
    "print(\"✓ HydraAALTD2024 PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5: AeonHydra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing AeonHydra...\n",
      "Model: AeonHydra(n_kernels=4,n_groups=16)\n",
      "Training completed in 0.101s\n",
      "Prediction completed in 0.014s\n",
      "Accuracy: 0.3641\n",
      "Predictions shape: (379,)\n",
      "✓ AeonHydra PASSED\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing AeonHydra...\")\n",
    "model5 = AeonAlgorithm(algorithm=\"hydra\", n_kernels=4, n_groups=16)\n",
    "print(f\"Model: {model5.name}\")\n",
    "\n",
    "start_time = time.time()\n",
    "model5.fit(dataset)\n",
    "train_time = time.time() - start_time\n",
    "print(f\"Training completed in {train_time:.3f}s\")\n",
    "\n",
    "start_time = time.time()\n",
    "predictions5 = model5.predict(dataset)\n",
    "pred_time = time.time() - start_time\n",
    "print(f\"Prediction completed in {pred_time:.3f}s\")\n",
    "\n",
    "accuracy5 = np.mean(predictions5 == y_test)\n",
    "print(f\"Accuracy: {accuracy5:.4f}\")\n",
    "print(f\"Predictions shape: {predictions5.shape}\")\n",
    "print(\"✓ AeonHydra PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 6: AeonQuant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing AeonQuant...\n",
      "Model: AeonQuant()\n",
      "Training completed in 1.252s\n",
      "Prediction completed in 0.062s\n",
      "Accuracy: 0.5409\n",
      "Predictions shape: (379,)\n",
      "✓ AeonQuant PASSED\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing AeonQuant...\")\n",
    "model6 = AeonAlgorithm(algorithm=\"quant\")\n",
    "print(f\"Model: {model6.name}\")\n",
    "\n",
    "start_time = time.time()\n",
    "model6.fit(dataset)\n",
    "train_time = time.time() - start_time\n",
    "print(f\"Training completed in {train_time:.3f}s\")\n",
    "\n",
    "start_time = time.time()\n",
    "predictions6 = model6.predict(dataset)\n",
    "pred_time = time.time() - start_time\n",
    "print(f\"Prediction completed in {pred_time:.3f}s\")\n",
    "\n",
    "accuracy6 = np.mean(predictions6 == y_test)\n",
    "print(f\"Accuracy: {accuracy6:.4f}\")\n",
    "print(f\"Predictions shape: {predictions6.shape}\")\n",
    "print(\"✓ AeonQuant PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 7: AeonRocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing AeonRocket...\n",
      "Model: AeonRocket(n_kernels=500)\n",
      "Training completed in 0.309s\n",
      "Prediction completed in 0.027s\n",
      "Accuracy: 0.4116\n",
      "Predictions shape: (379,)\n",
      "✓ AeonRocket PASSED\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing AeonRocket...\")\n",
    "model7 = AeonAlgorithm(algorithm=\"rocket\", n_kernels=500)\n",
    "print(f\"Model: {model7.name}\")\n",
    "\n",
    "start_time = time.time()\n",
    "model7.fit(dataset)\n",
    "train_time = time.time() - start_time\n",
    "print(f\"Training completed in {train_time:.3f}s\")\n",
    "\n",
    "start_time = time.time()\n",
    "predictions7 = model7.predict(dataset)\n",
    "pred_time = time.time() - start_time\n",
    "print(f\"Prediction completed in {pred_time:.3f}s\")\n",
    "\n",
    "accuracy7 = np.mean(predictions7 == y_test)\n",
    "print(f\"Accuracy: {accuracy7:.4f}\")\n",
    "print(f\"Predictions shape: {predictions7.shape}\")\n",
    "print(\"✓ AeonRocket PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 8: AeonMultiRocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing AeonMultiRocket...\n",
      "Model: AeonMultirocket(n_kernels=100,max_dilations_per_kernel=16)\n",
      "Training completed in 0.146s\n",
      "Prediction completed in 0.010s\n",
      "Accuracy: 0.4142\n",
      "Predictions shape: (379,)\n",
      "✓ AeonMultiRocket PASSED\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing AeonMultiRocket...\")\n",
    "model8 = AeonAlgorithm(algorithm=\"multirocket\", n_kernels=100, max_dilations_per_kernel=16)\n",
    "print(f\"Model: {model8.name}\")\n",
    "\n",
    "start_time = time.time()\n",
    "model8.fit(dataset)\n",
    "train_time = time.time() - start_time\n",
    "print(f\"Training completed in {train_time:.3f}s\")\n",
    "\n",
    "start_time = time.time()\n",
    "predictions8 = model8.predict(dataset)\n",
    "pred_time = time.time() - start_time\n",
    "print(f\"Prediction completed in {pred_time:.3f}s\")\n",
    "\n",
    "accuracy8 = np.mean(predictions8 == y_test)\n",
    "print(f\"Accuracy: {accuracy8:.4f}\")\n",
    "print(f\"Predictions shape: {predictions8.shape}\")\n",
    "print(\"✓ AeonMultiRocket PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "All 10 models tested on Pedestrian dataset (1% train, 1% test).\n",
    "Any failures will show full stack traces for debugging.\n",
    "\n",
    "**Ensembles compared**:\n",
    "- HydraQuantStackedAALTD2024: Old ensemble with data leakage (trains HYDRA on full data, gets logits on same data)\n",
    "- HydraQuantStacked: New clean ensemble with proper K-fold CV (avoids data leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing HydraQuantStackedAALTD2024...\n",
      "Model: HydraQuantStacked(hydra_k=4,hydra_g=16,quant_est=50)\n",
      "Training completed in 0.246s\n",
      "Prediction completed in 0.031s\n",
      "Accuracy: 0.5013\n",
      "Predictions shape: (379,)\n",
      "✓ HydraQuantStackedAALTD2024 PASSED\n",
      "\n",
      "--- Comparison ---\n",
      "QuantOriginal:     0.5303\n",
      "HydraOriginal:     0.3799\n",
      "QuantAALTD2024:    0.5145\n",
      "HydraAALTD2024:    0.3641\n",
      "Ensemble (new):    0.5013\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing HydraQuantStackedAALTD2024...\")\n",
    "model9 = HydraQuantStackedAALTD2024(\n",
    "    hydra_k=4, \n",
    "    hydra_g=16, \n",
    "    hydra_seed=42,\n",
    "    quant_estimators=50  # Reduced for faster testing\n",
    ")\n",
    "print(f\"Model: {model9.name}\")\n",
    "\n",
    "start_time = time.time()\n",
    "model9.fit(dataset)\n",
    "train_time = time.time() - start_time\n",
    "print(f\"Training completed in {train_time:.3f}s\")\n",
    "\n",
    "start_time = time.time()\n",
    "predictions9 = model9.predict(dataset)\n",
    "pred_time = time.time() - start_time\n",
    "print(f\"Prediction completed in {pred_time:.3f}s\")\n",
    "\n",
    "accuracy9 = np.mean(predictions9 == y_test)\n",
    "print(f\"Accuracy: {accuracy9:.4f}\")\n",
    "print(f\"Predictions shape: {predictions9.shape}\")\n",
    "print(\"✓ HydraQuantStackedAALTD2024 PASSED\")\n",
    "\n",
    "# Show improvement over individual models\n",
    "print(f\"\\n--- Comparison ---\")\n",
    "print(f\"QuantOriginal:     {accuracy1:.4f}\")\n",
    "print(f\"HydraOriginal:     {accuracy2:.4f}\") \n",
    "print(f\"QuantAALTD2024:    {accuracy3:.4f}\")\n",
    "print(f\"HydraAALTD2024:    {accuracy4:.4f}\")\n",
    "print(f\"Ensemble (new):    {accuracy9:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing HydraQuantStacked (Clean Ensemble)...\n",
      "Model: HydraQuantStacked(folds=3,k=4,g=16,est=50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/urav/code/research/venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 0.441s\n",
      "Prediction completed in 0.040s\n",
      "Accuracy: 0.5066\n",
      "Predictions shape: (379,)\n",
      "✓ HydraQuantStacked PASSED\n",
      "\n",
      "--- Final Comparison ---\n",
      "QuantOriginal:               0.5303\n",
      "HydraOriginal:               0.3799\n",
      "QuantAALTD2024:              0.5145\n",
      "HydraAALTD2024:              0.3641\n",
      "Ensemble (old, data leak):   0.5013\n",
      "Ensemble (new, clean CV):    0.5066\n",
      "\n",
      "🏆 Best performer: QuantOriginal\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing HydraQuantStacked (Clean Ensemble)...\")\n",
    "model10 = HydraQuantStacked(\n",
    "    n_folds=3,           # Reduced for faster testing\n",
    "    hydra_k=4, \n",
    "    hydra_g=16, \n",
    "    hydra_seed=42,\n",
    "    n_estimators=50      # Reduced for faster testing\n",
    ")\n",
    "print(f\"Model: {model10.name}\")\n",
    "\n",
    "start_time = time.time()\n",
    "model10.fit(dataset)\n",
    "train_time = time.time() - start_time\n",
    "print(f\"Training completed in {train_time:.3f}s\")\n",
    "\n",
    "start_time = time.time()\n",
    "predictions10 = model10.predict(dataset)\n",
    "pred_time = time.time() - start_time\n",
    "print(f\"Prediction completed in {pred_time:.3f}s\")\n",
    "\n",
    "accuracy10 = np.mean(predictions10 == y_test)\n",
    "print(f\"Accuracy: {accuracy10:.4f}\")\n",
    "print(f\"Predictions shape: {predictions10.shape}\")\n",
    "print(\"✓ HydraQuantStacked PASSED\")\n",
    "\n",
    "# Updated comparison\n",
    "print(f\"\\n--- Final Comparison ---\")\n",
    "print(f\"QuantOriginal:               {accuracy1:.4f}\")\n",
    "print(f\"HydraOriginal:               {accuracy2:.4f}\") \n",
    "print(f\"QuantAALTD2024:              {accuracy3:.4f}\")\n",
    "print(f\"HydraAALTD2024:              {accuracy4:.4f}\")\n",
    "print(f\"Ensemble (old, data leak):   {accuracy9:.4f}\")\n",
    "print(f\"Ensemble (new, clean CV):    {accuracy10:.4f}\")\n",
    "\n",
    "# Highlight best performer\n",
    "best_algo = np.argmax([accuracy1, accuracy2, accuracy3, accuracy4, accuracy9, accuracy10])\n",
    "algos = [\"QuantOriginal\", \"HydraOriginal\", \"QuantAALTD2024\", \"HydraAALTD2024\", \"Old Ensemble\", \"New Ensemble\"]\n",
    "print(f\"\\n🏆 Best performer: {algos[best_algo]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 10: HydraQuantStacked (New Clean Ensemble)\n",
    "\n",
    "Our new stacked ensemble with proper cross-validation to avoid data leakage."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
