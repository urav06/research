{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quant AALTD Benchmark\n",
    "\n",
    "Simple benchmark notebook to test the quant AALTD algorithm.\n",
    "- Algorithm: QuantAALTD2024\n",
    "- Metrics: Runtime (train/predict), accuracy, memory usage\n",
    "- Dataset: Configurable via DATASET_NAME variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION - Change this to test different datasets\n",
    "DATASET_NAME = \"Pedestrian\"  # Change this to any UCR dataset name\n",
    "TRAIN_PCT = 100  # Percentage of training data to use\n",
    "TEST_PCT = 100   # Percentage of test data to use\n",
    "NUM_ESTIMATORS = 200  # Number of estimators for QuantAALTD2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Paths configured\n"
     ]
    }
   ],
   "source": [
    "# Setup paths BEFORE importing tsckit\n",
    "import sys\n",
    "\n",
    "ROOT_DIR = '/Users/urav/code/research'\n",
    "\n",
    "# Add algorithm code paths\n",
    "sys.path.extend([\n",
    "    f'{ROOT_DIR}',                    # For tsckit package\n",
    "    f'{ROOT_DIR}/quant/code',         # For original quant.py\n",
    "    f'{ROOT_DIR}/hydra/code',         # For original hydra.py\n",
    "    f'{ROOT_DIR}/aaltd2024/code',     # For quant_aaltd.py, hydra_gpu.py, utils.py, ridge.py\n",
    "])\n",
    "\n",
    "\n",
    "print(\"✓ Paths configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/urav/code/research/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries imported\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import time\n",
    "import psutil\n",
    "import numpy as np\n",
    "from tsckit import MonsterDataset, QuantAALTD2024\n",
    "\n",
    "print(\"✓ Libraries imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial memory usage: 366.1 MB\n"
     ]
    }
   ],
   "source": [
    "# Memory usage helper\n",
    "def get_memory_usage():\n",
    "    return psutil.Process().memory_info().rss / 1024 / 1024  # MB\n",
    "\n",
    "print(f\"Initial memory usage: {get_memory_usage():.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Pedestrian dataset...\n",
      "Dataset: Pedestrian (fold 0):\n",
      "  Shape: 1 channels x 24 time points\n",
      "  Classes: 82\n",
      "  Total samples: 189621\n",
      "  Train samples: 151696 (100%)\n",
      "  Test samples: 37925 (100%)\n",
      "Test samples: 37925, Classes: 82\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "print(f\"Loading {DATASET_NAME} dataset...\")\n",
    "dataset = MonsterDataset(DATASET_NAME, fold=0, train_pct=TRAIN_PCT, test_pct=TEST_PCT)\n",
    "print(f\"Dataset: {dataset.info()}\")\n",
    "\n",
    "# Get test labels for accuracy calculation\n",
    "_, y_test = dataset.get_arrays(\"test\")\n",
    "print(f\"Test samples: {len(y_test)}, Classes: {len(np.unique(y_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing QuantAALTD2024...\n",
      "Model: QuantAALTD2024(n_estimators=200)\n",
      "Memory after initialization: 391.4 MB\n"
     ]
    }
   ],
   "source": [
    "# Initialize QuantAALTD2024 model\n",
    "print(\"Initializing QuantAALTD2024...\")\n",
    "model = QuantAALTD2024(num_estimators=NUM_ESTIMATORS)\n",
    "print(f\"Model: {model.name}\")\n",
    "\n",
    "memory_after_init = get_memory_usage()\n",
    "print(f\"Memory after initialization: {memory_after_init:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TRAINING PHASE ===\n",
      "Training time: 20.607 seconds\n",
      "Memory usage during training: +251.5 MB\n",
      "Total memory after training: 642.8 MB\n"
     ]
    }
   ],
   "source": [
    "# Training phase\n",
    "print(\"\\n=== TRAINING PHASE ===\")\n",
    "memory_before_train = get_memory_usage()\n",
    "train_start_time = time.time()\n",
    "\n",
    "model.fit(dataset)\n",
    "\n",
    "train_end_time = time.time()\n",
    "memory_after_train = get_memory_usage()\n",
    "\n",
    "train_time = train_end_time - train_start_time\n",
    "train_memory_delta = memory_after_train - memory_before_train\n",
    "\n",
    "print(f\"Training time: {train_time:.3f} seconds\")\n",
    "print(f\"Memory usage during training: +{train_memory_delta:.1f} MB\")\n",
    "print(f\"Total memory after training: {memory_after_train:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PREDICTION PHASE ===\n",
      "Prediction time: 2.248 seconds\n",
      "Memory usage during prediction: +969.1 MB\n",
      "Total memory after prediction: 1617.3 MB\n"
     ]
    }
   ],
   "source": [
    "# Prediction phase\n",
    "print(\"\\n=== PREDICTION PHASE ===\")\n",
    "memory_before_pred = get_memory_usage()\n",
    "pred_start_time = time.time()\n",
    "\n",
    "predictions = model.predict(dataset)\n",
    "\n",
    "pred_end_time = time.time()\n",
    "memory_after_pred = get_memory_usage()\n",
    "\n",
    "pred_time = pred_end_time - pred_start_time\n",
    "pred_memory_delta = memory_after_pred - memory_before_pred\n",
    "\n",
    "print(f\"Prediction time: {pred_time:.3f} seconds\")\n",
    "print(f\"Memory usage during prediction: +{pred_memory_delta:.1f} MB\")\n",
    "print(f\"Total memory after prediction: {memory_after_pred:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESULTS ===\n",
      "Accuracy: 0.7741 (77.41%)\n",
      "Predictions shape: (37925,)\n",
      "Correct predictions: 29356 / 37925\n"
     ]
    }
   ],
   "source": [
    "# Results evaluation\n",
    "print(\"\\n=== RESULTS ===\")\n",
    "accuracy = np.mean(predictions == y_test)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"Predictions shape: {predictions.shape}\")\n",
    "print(f\"Correct predictions: {np.sum(predictions == y_test)} / {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== BENCHMARK SUMMARY ===\n",
      "Algorithm: QuantAALTD2024(n_estimators=200)\n",
      "Dataset: Pedestrian (Train: 151696, Test: 37925)\n",
      "\n",
      "Performance:\n",
      "  - Training time: 20.607s\n",
      "  - Prediction time: 2.248s\n",
      "  - Total time: 22.855s\n",
      "  - Accuracy: 0.7741\n",
      "\n",
      "Memory usage:\n",
      "  - Training: +251.5 MB\n",
      "  - Prediction: +969.1 MB\n",
      "  - Peak: 1617.3 MB\n"
     ]
    }
   ],
   "source": [
    "# Summary report\n",
    "print(\"\\n=== BENCHMARK SUMMARY ===\")\n",
    "print(f\"Algorithm: {model.name}\")\n",
    "print(f\"Dataset: {DATASET_NAME} (Train: {len(dataset.train_indices)}, Test: {len(y_test)})\")\n",
    "print(f\"\")\n",
    "print(f\"Performance:\")\n",
    "print(f\"  - Training time: {train_time:.3f}s\")\n",
    "print(f\"  - Prediction time: {pred_time:.3f}s\")\n",
    "print(f\"  - Total time: {train_time + pred_time:.3f}s\")\n",
    "print(f\"  - Accuracy: {accuracy:.4f}\")\n",
    "print(f\"\")\n",
    "print(f\"Memory usage:\")\n",
    "print(f\"  - Training: +{train_memory_delta:.1f} MB\")\n",
    "print(f\"  - Prediction: +{pred_memory_delta:.1f} MB\")\n",
    "print(f\"  - Peak: {memory_after_pred:.1f} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
