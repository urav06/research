{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quant AALTD Benchmark\n",
    "\n",
    "Simple benchmark notebook to test the quant AALTD algorithm.\n",
    "- Algorithm: QuantAALTD2024\n",
    "- Metrics: Runtime (train/predict), accuracy, memory usage\n",
    "- Dataset: Configurable via DATASET_NAME variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION - Change this to test different datasets\n",
    "DATASET_NAME = \"Pedestrian\"  # Change this to any UCR dataset name\n",
    "TRAIN_PCT = 1.0  # Percentage of training data to use\n",
    "TEST_PCT = 1.0   # Percentage of test data to use\n",
    "NUM_ESTIMATORS = 200  # Number of estimators for QuantAALTD2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup paths BEFORE importing tsckit\n",
    "import sys\n",
    "\n",
    "ROOT_DIR = '/Users/urav/code/research'\n",
    "\n",
    "# Add algorithm code paths\n",
    "sys.path.extend([\n",
    "    f'{ROOT_DIR}',                    # For tsckit package\n",
    "    f'{ROOT_DIR}/quant/code',         # For original quant.py\n",
    "    f'{ROOT_DIR}/hydra/code',         # For original hydra.py\n",
    "    f'{ROOT_DIR}/aaltd2024/code',     # For quant_aaltd.py, hydra_gpu.py, utils.py, ridge.py\n",
    "])\n",
    "\n",
    "\n",
    "print(\"✓ Paths configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import time\n",
    "import psutil\n",
    "import numpy as np\n",
    "from tsckit import MonsterDataset, QuantAALTD2024\n",
    "\n",
    "print(\"✓ Libraries imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory usage helper\n",
    "def get_memory_usage():\n",
    "    return psutil.Process().memory_info().rss / 1024 / 1024  # MB\n",
    "\n",
    "print(f\"Initial memory usage: {get_memory_usage():.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "print(f\"Loading {DATASET_NAME} dataset...\")\n",
    "dataset = MonsterDataset(DATASET_NAME, fold=0, train_pct=TRAIN_PCT, test_pct=TEST_PCT)\n",
    "print(f\"Dataset: {dataset.info()}\")\n",
    "\n",
    "# Get test labels for accuracy calculation\n",
    "_, y_test = dataset.get_arrays(\"test\")\n",
    "print(f\"Test samples: {len(y_test)}, Classes: {len(np.unique(y_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize QuantAALTD2024 model\n",
    "print(\"Initializing QuantAALTD2024...\")\n",
    "model = QuantAALTD2024(num_estimators=NUM_ESTIMATORS)\n",
    "print(f\"Model: {model.name}\")\n",
    "\n",
    "memory_after_init = get_memory_usage()\n",
    "print(f\"Memory after initialization: {memory_after_init:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training phase\n",
    "print(\"\\n=== TRAINING PHASE ===\")\n",
    "memory_before_train = get_memory_usage()\n",
    "train_start_time = time.time()\n",
    "\n",
    "model.fit(dataset)\n",
    "\n",
    "train_end_time = time.time()\n",
    "memory_after_train = get_memory_usage()\n",
    "\n",
    "train_time = train_end_time - train_start_time\n",
    "train_memory_delta = memory_after_train - memory_before_train\n",
    "\n",
    "print(f\"Training time: {train_time:.3f} seconds\")\n",
    "print(f\"Memory usage during training: +{train_memory_delta:.1f} MB\")\n",
    "print(f\"Total memory after training: {memory_after_train:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction phase\n",
    "print(\"\\n=== PREDICTION PHASE ===\")\n",
    "memory_before_pred = get_memory_usage()\n",
    "pred_start_time = time.time()\n",
    "\n",
    "predictions = model.predict(dataset)\n",
    "\n",
    "pred_end_time = time.time()\n",
    "memory_after_pred = get_memory_usage()\n",
    "\n",
    "pred_time = pred_end_time - pred_start_time\n",
    "pred_memory_delta = memory_after_pred - memory_before_pred\n",
    "\n",
    "print(f\"Prediction time: {pred_time:.3f} seconds\")\n",
    "print(f\"Memory usage during prediction: +{pred_memory_delta:.1f} MB\")\n",
    "print(f\"Total memory after prediction: {memory_after_pred:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results evaluation\n",
    "print(\"\\n=== RESULTS ===\")\n",
    "accuracy = np.mean(predictions == y_test)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"Predictions shape: {predictions.shape}\")\n",
    "print(f\"Correct predictions: {np.sum(predictions == y_test)} / {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary report\n",
    "print(\"\\n=== BENCHMARK SUMMARY ===\")\n",
    "print(f\"Algorithm: {model.name}\")\n",
    "print(f\"Dataset: {DATASET_NAME} (Train: {len(dataset.train_indices)}, Test: {len(y_test)})\")\n",
    "print(f\"\")\n",
    "print(f\"Performance:\")\n",
    "print(f\"  - Training time: {train_time:.3f}s\")\n",
    "print(f\"  - Prediction time: {pred_time:.3f}s\")\n",
    "print(f\"  - Total time: {train_time + pred_time:.3f}s\")\n",
    "print(f\"  - Accuracy: {accuracy:.4f}\")\n",
    "print(f\"\")\n",
    "print(f\"Memory usage:\")\n",
    "print(f\"  - Training: +{train_memory_delta:.1f} MB\")\n",
    "print(f\"  - Prediction: +{pred_memory_delta:.1f} MB\")\n",
    "print(f\"  - Peak: {memory_after_pred:.1f} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
